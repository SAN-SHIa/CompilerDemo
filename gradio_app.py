#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LR(1)ç¼–è¯‘åŸç†åˆ†æå™¨ Gradio å¯è§†åŒ–ç•Œé¢
"""

import gradio as gr
import subprocess
import os
import tempfile
import shutil
from pathlib import Path
import re

# å¯¼å…¥Python LR(1)åˆ†æå™¨
try:
    from python_lr1_parser import create_c_grammar, LR1Parser
    from lr1_visualizer import (DFAVisualizer, SyntaxTreeBuilder, SyntaxTreeVisualizer,
                               generate_lr1_table_markdown, generate_analysis_steps_markdown)
    PYTHON_BACKEND_AVAILABLE = True
except ImportError as e:
    print(f"Pythonåç«¯ä¸å¯ç”¨: {e}")
    PYTHON_BACKEND_AVAILABLE = False

# å·¥ä½œç›®å½•è®¾ç½®
WORK_DIR = Path(__file__).parent.resolve()
CPP_EXECUTABLE = WORK_DIR / "exe" / "main"
OUTCOME_DIR = WORK_DIR / "outcome"

# é¢„å®šä¹‰çš„æ–‡æ³•é€‰é¡¹ - ç®€åŒ–ç‰ˆæœ¬ï¼Œåªä¿ç•™èƒ½æ­£ç¡®å¤„ç†çš„
GRAMMARS = {
    "æ–‡æ³•1: Sâ†’CC, Câ†’cC|d": {
        "number": 1,
        "productions": ["S â†’ CC", "C â†’ cC", "C â†’ d"],
        "example_input": "ccd"
    },
    "æ–‡æ³•2: Sâ†’L=S|R, Lâ†’aLR|b, Râ†’a": {
        "number": 2, 
        "productions": ["S â†’ L=S", "S â†’ R", "L â†’ aLR", "L â†’ b", "R â†’ a"],
        "example_input": "aba=b=a"
    },
    "æ–‡æ³•3: Sâ†’aLb|a, Lâ†’aR, Râ†’LR|b": {
        "number": 3,
        "productions": ["S â†’ aLb", "S â†’ a", "L â†’ aR", "R â†’ LR", "R â†’ b"],
        "example_input": "aaabbb"
    },
    "æ–‡æ³•4: Sâ†’L=LR|R, Lâ†’aR|b, Râ†’L": {
        "number": 4,
        "productions": ["S â†’ L=LR", "S â†’ R", "L â†’ aR", "L â†’ b", "R â†’ L"],
        "example_input": "b=abab"
    },
    "æ–‡æ³•5: Sâ†’(L)|a, Lâ†’L,S|S": {
        "number": 5,
        "productions": ["S â†’ (L)", "S â†’ a", "L â†’ L,S", "L â†’ S"],
        "example_input": "((a),a)"
    },
    "æ–‡æ³•6: Sâ†’(S)S|Îµ": {
        "number": 6,
        "productions": ["S â†’ (S)S", "S â†’ Îµ"],
        "example_input": "()()"
    },
    "Cè¯­è¨€1: ç®€å•èµ‹å€¼è¯­å¥ - Sâ†’id=E, Eâ†’E+T|T, Tâ†’T*F|F, Fâ†’(E)|id|num": {
        "number": 7,
        "productions": ["S â†’ id=E", "E â†’ E+T", "E â†’ T", "T â†’ T*F", "T â†’ F", "F â†’ (E)", "F â†’ id", "F â†’ num"],
        "example_input": "x=a+b*c"
    },
    "Cè¯­è¨€2: ifè¯­å¥ - Sâ†’if(E)S|id=E, Eâ†’E==T|T, Tâ†’id|num": {
        "number": 8,
        "productions": ["S â†’ if(E)S", "S â†’ id=E", "E â†’ E==T", "E â†’ T", "T â†’ id", "T â†’ num"],
        "example_input": "if(x==1)y=2"
    },
    "Cè¯­è¨€3: å˜é‡å£°æ˜ - Sâ†’T id, Tâ†’int|float|char": {
        "number": 9,
        "productions": ["S â†’ T id", "T â†’ int", "T â†’ float", "T â†’ char"],
        "example_input": "int x"
    },
    "Cè¯­è¨€4: whileå¾ªç¯ - Sâ†’while(E)S|id=E, Eâ†’E<T|T, Tâ†’T+F|F, Fâ†’id|num": {
        "number": 10,
        "productions": ["S â†’ while(E)S", "S â†’ id=E", "E â†’ E<T", "E â†’ T", "T â†’ T+F", "T â†’ F", "F â†’ id", "F â†’ num"],
        "example_input": "while(i<10)i=i+1"
    },
    "Cè¯­è¨€5: ç®—æœ¯è¡¨è¾¾å¼ - Eâ†’E+T|E-T|T, Tâ†’T*F|T/F|F, Fâ†’(E)|id|num": {
        "number": 11,
        "productions": ["E â†’ E+T", "E â†’ E-T", "E â†’ T", "T â†’ T*F", "T â†’ T/F", "T â†’ F", "F â†’ (E)", "F â†’ id", "F â†’ num"],
        "example_input": "a+b*c-d"
    }
}

def create_cpp_file_with_grammar(grammar_key, input_string):
    """æ ¹æ®é€‰æ‹©çš„æ–‡æ³•åˆ›å»ºä¸´æ—¶çš„C++æ–‡ä»¶"""
    if grammar_key not in GRAMMARS:
        return None
        
    grammar_info = GRAMMARS[grammar_key]
    grammar_number = grammar_info["number"]
    
    # è¯»å–åŸå§‹main.cppæ–‡ä»¶
    main_cpp_path = WORK_DIR / "main.cpp"
    with open(main_cpp_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # è¯»å–functions.cppæ–‡ä»¶
    functions_cpp_path = WORK_DIR / "functions.cpp"
    with open(functions_cpp_path, 'r', encoding='utf-8') as f:
        functions_content = f.read()
    
    # ä¿®æ”¹æ–‡æ³•ç¼–å·å’Œè¾“å…¥ä¸²
    # æ›¿æ¢createGrammarè°ƒç”¨ä¸­çš„å‚æ•°
    content = content.replace('createGrammar(1)', f'createGrammar({grammar_number})')
    
    # æ›¿æ¢è¾“å…¥ä¸²
    old_input_line = 'std::string inputString = "cc";'
    new_input_line = f'std::string inputString = "{input_string}";'
    content = content.replace(old_input_line, new_input_line)
    
    # å¦‚æœæ˜¯Cè¯­è¨€æ–‡æ³•ï¼ˆç¼–å·7-24ï¼‰ï¼Œæˆ‘ä»¬éœ€è¦åœ¨functions.cppä¸­æ·»åŠ å¯¹åº”çš„æ–‡æ³•å®šä¹‰
    if grammar_number >= 7:
        functions_content = add_c_grammar_support(functions_content, grammar_number, grammar_info)
    
    # å°†#include "functions.cpp"æ›¿æ¢ä¸ºç›´æ¥åµŒå…¥functions.cppçš„å†…å®¹
    include_line = '#include "functions.cpp"'
    if include_line in content:
        content = content.replace(include_line, functions_content)
    
    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
    temp_cpp = tempfile.NamedTemporaryFile(mode='w', suffix='.cpp', delete=False, encoding='utf-8')
    temp_cpp.write(content)
    temp_cpp.close()
    
    return temp_cpp.name

def update_cpp_grammar_definitions(grammar_selections):
    """æ›´æ–°C++æ–‡ä»¶ä¸­çš„æ–‡æ³•å®šä¹‰ä»¥æ”¯æŒå¤šä¸ªæ–‡æ³•"""
    functions_cpp_path = WORK_DIR / "functions.cpp"
    main_cpp_path = WORK_DIR / "main.cpp"
    
    # è¿™é‡Œæˆ‘ä»¬éœ€è¦ä¿®æ”¹main.cppä¸­çš„createGrammarå‡½æ•°æ¥æ”¯æŒæ›´å¤šæ–‡æ³•
    # ä¸ºç®€åŒ–ï¼Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨ç°æœ‰çš„æ–‡æ³•1
    pass

def compile_and_run_analysis(grammar_key, input_string):
    """ç¼–è¯‘å¹¶è¿è¡ŒLR(1)åˆ†æ"""
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        OUTCOME_DIR.mkdir(exist_ok=True)
        
        # åˆ›å»ºå¸¦æœ‰æŒ‡å®šæ–‡æ³•çš„ä¸´æ—¶C++æ–‡ä»¶
        temp_cpp_file = create_cpp_file_with_grammar(grammar_key, input_string)
        if not temp_cpp_file:
            return "é”™è¯¯ï¼šæ— æ•ˆçš„æ–‡æ³•é€‰æ‹©", "", "", ""
        
        # ç¼–è¯‘ä¸´æ—¶C++æ–‡ä»¶
        temp_executable = temp_cpp_file.replace('.cpp', '')
        compile_cmd = [
            "g++", "-std=c++17", "-o", temp_executable, temp_cpp_file
        ]
        
        compile_result = subprocess.run(
            compile_cmd, 
            capture_output=True, 
            text=True, 
            cwd=WORK_DIR
        )
        
        if compile_result.returncode != 0:
            os.unlink(temp_cpp_file)
            return f"ç¼–è¯‘é”™è¯¯:\n{compile_result.stderr}", "", "", ""
        
        # è¿è¡Œåˆ†æç¨‹åº
        run_result = subprocess.run(
            [temp_executable],
            capture_output=True,
            text=True,
            cwd=WORK_DIR
        )
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(temp_cpp_file)
        if os.path.exists(temp_executable):
            os.unlink(temp_executable)
        
        if run_result.returncode != 0:
            return f"è¿è¡Œé”™è¯¯:\n{run_result.stderr}", "", "", ""
        
        # è¯»å–è¾“å‡ºç»“æœ
        console_output = run_result.stdout
        
        # è¯»å–ç”Ÿæˆçš„æ–‡ä»¶ï¼Œä½¿ç”¨åŠ¨æ€æ–‡ä»¶å
        grammar_info = GRAMMARS[grammar_key]
        grammar_number = grammar_info["number"]
        lr1_table_file = OUTCOME_DIR / f"lr1_table_grammar{grammar_number}.md"
        lr1_analysis_file = OUTCOME_DIR / f"lr1_analysis_grammar{grammar_number}.md"
        dfa_image_file = OUTCOME_DIR / f"dfa_grammar{grammar_number}.png"
        
        # å¦‚æœåŠ¨æ€æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤çš„grammar1æ–‡ä»¶
        if not lr1_table_file.exists():
            lr1_table_file = OUTCOME_DIR / "lr1_table_grammar1.md"
        if not lr1_analysis_file.exists():
            lr1_analysis_file = OUTCOME_DIR / "lr1_analysis_grammar1.md"
        if not dfa_image_file.exists():
            dfa_image_file = OUTCOME_DIR / "dfa_grammar1.png"
        
        table_content = ""
        analysis_content = ""
        dfa_image_path = None
        
        if lr1_table_file.exists():
            with open(lr1_table_file, 'r', encoding='utf-8') as f:
                table_content = f.read()
        
        if lr1_analysis_file.exists():
            with open(lr1_analysis_file, 'r', encoding='utf-8') as f:
                analysis_content = f.read()
        
        if dfa_image_file.exists():
            dfa_image_path = str(dfa_image_file)
        
        return console_output, table_content, analysis_content, dfa_image_path
        
    except Exception as e:
        return f"æ‰§è¡Œé”™è¯¯: {str(e)}", "", "", ""

def preprocess_c_code(code):
    """
    é¢„å¤„ç†Cè¯­è¨€ä»£ç ï¼Œè¿›è¡Œè¯æ³•åˆ†æå¹¶è½¬æ¢ä¸ºé€‚åˆè¯­æ³•åˆ†æçš„tokenåºåˆ—
    """
    import re
    
    # å»é™¤æ³¨é‡Š
    code = re.sub(r'//.*', '', code)  # å•è¡Œæ³¨é‡Š
    code = re.sub(r'/\*.*?\*/', '', code, flags=re.DOTALL)  # å¤šè¡Œæ³¨é‡Š
    
    # å®šä¹‰Cè¯­è¨€å…³é”®å­—å’Œæ“ä½œç¬¦çš„æ˜ å°„
    token_map = {
        # å…³é”®å­—
        'int': 'int', 'float': 'float', 'char': 'char', 'void': 'void',
        'if': 'if', 'else': 'else', 'while': 'while', 'for': 'for',
        'switch': 'switch', 'case': 'case', 'default': 'default',
        
        # æ“ä½œç¬¦
        '++': '++', '--': '--', 
        '==': '==', '!=': '!=', '<=': '<=', '>=': '>=',
        '&&': '&&', '||': '||',
        '->': '->', '<<': '<<', '>>': '>>',
        
        # å•å­—ç¬¦æ“ä½œç¬¦
        '+': '+', '-': '-', '*': '*', '/': '/', '%': '%',
        '=': '=', '<': '<', '>': '>', '!': '!', '&': '&', '|': '|',
        '?': '?', ':': ':', ';': ';', ',': ',', '.': '.',
        '(': '(', ')': ')', '[': '[', ']': ']', '{': '{', '}': '}'
    }
    
    # è¯æ³•åˆ†ææ­£åˆ™è¡¨è¾¾å¼ - ç¡®ä¿å…³é”®å­—åœ¨æ ‡è¯†ç¬¦ä¹‹å‰åŒ¹é…
    patterns = [
        # åŒå­—ç¬¦æ“ä½œç¬¦å¿…é¡»åœ¨å•å­—ç¬¦æ“ä½œç¬¦ä¹‹å‰æ£€æŸ¥
        (r'\+\+|--|==|!=|<=|>=|&&|\|\||->|<<|>>', 'OP2'),
        # å…³é”®å­—å¿…é¡»åœ¨æ ‡è¯†ç¬¦ä¹‹å‰æ£€æŸ¥ï¼Œå¹¶ä¸”ä½¿ç”¨\bç¡®ä¿å®Œæ•´åŒ¹é…è¯è¾¹ç•Œ
        (r'\bint\b', 'int'),
        (r'\bfloat\b', 'float'),
        (r'\bchar\b', 'char'),
        (r'\bvoid\b', 'void'),
        (r'\bif\b', 'if'),
        (r'\belse\b', 'else'),
        (r'\bwhile\b', 'while'),
        (r'\bfor\b', 'for'),
        (r'\bswitch\b', 'switch'),
        (r'\bcase\b', 'case'),
        (r'\bdefault\b', 'default'),
        # æ ‡è¯†ç¬¦åœ¨å…³é”®å­—ä¹‹ååŒ¹é…
        (r'\b[a-zA-Z_][a-zA-Z0-9_]*\b', 'ID'),
        (r'\b\d+(?:\.\d+)?\b', 'NUM'),
        (r'[+\-*/=%<>!&|?:;,.\[\](){}]', 'OP1'),
        (r'\s+', 'SPACE')
    ]
    
    tokens = []
    pos = 0
    debug = True  # å¯ç”¨è°ƒè¯•è¾“å‡º
    
    if debug:
        print(f"å¼€å§‹é¢„å¤„ç†ä»£ç : '{code}'")
        
    while pos < len(code):
        matched = False
        for pattern, token_type in patterns:
            regex = re.compile(pattern)
            match = regex.match(code, pos)
            if match:
                value = match.group(0)
                if token_type != 'SPACE':  # å¿½ç•¥ç©ºç™½å­—ç¬¦
                    if token_type == 'ID':
                        tokens.append('id')
                        if debug:
                            print(f"æ ‡è¯†ç¬¦: '{value}' -> 'id'")
                    elif token_type == 'NUM':
                        tokens.append('num')
                        if debug:
                            print(f"æ•°å­—: '{value}' -> 'num'")
                    elif token_type in ['int', 'float', 'char', 'void', 'if', 'else', 'while', 'for', 'switch', 'case', 'default']:
                        tokens.append(token_type)
                        if debug:
                            print(f"å…³é”®å­—: '{value}' -> '{token_type}'")
                    else:  # OP1 æˆ– OP2
                        tokens.append(value)
                        if debug:
                            print(f"æ“ä½œç¬¦: '{value}' -> '{value}'")
                else:
                    if debug:
                        print(f"å¿½ç•¥ç©ºç™½: '{value}'")
                pos = match.end()
                matched = True
                break
        
        if not matched:
            if debug:
                print(f"è·³è¿‡æ— æ³•è¯†åˆ«çš„å­—ç¬¦: '{code[pos]}'")
            pos += 1  # è·³è¿‡æ— æ³•è¯†åˆ«çš„å­—ç¬¦
    
    if debug:
        print(f"é¢„å¤„ç†åçš„è¯æ³•å•å…ƒåˆ—è¡¨: {tokens}")
        
    # è¿”å›tokenåˆ—è¡¨
    return tokens

def add_c_grammar_support(functions_content, grammar_number, grammar_info):
    """åœ¨functions.cppå†…å®¹ä¸­æ·»åŠ Cè¯­è¨€æ–‡æ³•æ”¯æŒ"""
    
    # æŸ¥æ‰¾createGrammarå‡½æ•°çš„ä½ç½®
    create_grammar_start = functions_content.find("Grammar createGrammar(int grammarNumber)")
    if create_grammar_start == -1:
        return functions_content
    
    # æŸ¥æ‰¾switchè¯­å¥çš„ä½ç½®
    switch_start = functions_content.find("switch (grammarNumber)", create_grammar_start)
    if switch_start == -1:
        return functions_content
    
    # æŸ¥æ‰¾default caseçš„ä½ç½®ï¼Œåœ¨å®ƒä¹‹å‰æ’å…¥æ–°çš„case
    default_pos = functions_content.find("default:", switch_start)
    if default_pos == -1:
        return functions_content
    
    # æ ¹æ®æ–‡æ³•ç¼–å·ç”Ÿæˆå¯¹åº”çš„C++ä»£ç 
    case_code = generate_grammar_case_code(grammar_number, grammar_info)
    
    # åœ¨defaultä¹‹å‰æ’å…¥æ–°çš„case
    modified_content = (
        functions_content[:default_pos] + 
        case_code + 
        functions_content[default_pos:]
    )
    
    return modified_content

def generate_grammar_case_code(grammar_number, grammar_info):
    """æ ¹æ®æ–‡æ³•ä¿¡æ¯ç”ŸæˆC++çš„caseä»£ç """
    productions = grammar_info["productions"]
    
    case_lines = [f"    case {grammar_number}: // Cè¯­è¨€æ–‡æ³•{grammar_number}"]
    case_lines.append("    {")
    
    # ä¸ºæ¯ä¸ªäº§ç”Ÿå¼ç”ŸæˆaddProductionè°ƒç”¨
    for production in productions:
        # è§£æäº§ç”Ÿå¼ï¼Œä¾‹å¦‚ "S â†’ id=E" å˜æˆ left="S", right=["id", "=", "E"]
        left, right = production.split(" â†’ ")
        left = left.strip()
        
        # å¤„ç†å³éƒ¨ï¼Œåˆ†å‰²ç¬¦å·
        right_symbols = []
        if right.strip() == "Îµ":
            right_symbols = []  # ç©ºäº§ç”Ÿå¼
        else:
            # ç®€å•åˆ†å‰²ï¼Œå¯èƒ½éœ€è¦æ›´å¤æ‚çš„è§£æ
            right_symbols = parse_production_right(right.strip())
        
        # ç”ŸæˆC++ä»£ç 
        if not right_symbols:  # ç©ºäº§ç”Ÿå¼
            case_lines.append(f'        grammar.addProduction("{left}", {{}});')
        else:
            symbols_str = ', '.join([f'"{symbol}"' for symbol in right_symbols])
            case_lines.append(f'        grammar.addProduction("{left}", {{{symbols_str}}});')
    
    case_lines.append("        break;")
    case_lines.append("    }")
    case_lines.append("")
    
    return "\n".join(case_lines)

def parse_production_right(right_part):
    """è§£æäº§ç”Ÿå¼å³éƒ¨ï¼Œå°†å…¶åˆ†å‰²ä¸ºç¬¦å·åˆ—è¡¨"""
    import re
    
    # å¤„ç†ç‰¹æ®Šç¬¦å·çš„æ˜ å°„
    symbols = []
    i = 0
    while i < len(right_part):
        if i < len(right_part) - 1:
            # æ£€æŸ¥åŒå­—ç¬¦æ“ä½œç¬¦
            two_char = right_part[i:i+2]
            if two_char in ['==', '!=', '<=', '>=', '&&', '||', '++', '--']:
                symbols.append(two_char)
                i += 2
                continue
        
        # å•å­—ç¬¦å¤„ç†
        char = right_part[i]
        if char.isalnum() or char == '_':
            # æ”¶é›†æ ‡è¯†ç¬¦æˆ–å…³é”®å­—
            start = i
            while i < len(right_part) and (right_part[i].isalnum() or right_part[i] == '_'):
                i += 1
            symbols.append(right_part[start:i])
        elif char in '()[]{}=+*/<>!&|?:;,.':
            symbols.append(char)
            i += 1
        else:
            i += 1  # è·³è¿‡ç©ºæ ¼ç­‰
    
    return symbols

def analyze_lr1_with_preprocessing(grammar_key, input_string, use_preprocessing=True):
    """ä¸»è¦çš„åˆ†æå‡½æ•°ï¼Œæ”¯æŒCè¯­è¨€ä»£ç é¢„å¤„ç†"""
    if not grammar_key or not input_string.strip():
        return "è¯·é€‰æ‹©æ–‡æ³•å¹¶è¾“å…¥å¾…åˆ†æçš„å­—ç¬¦ä¸²", "", "", None, None
    
    grammar_info = GRAMMARS[grammar_key]
    grammar_number = grammar_info["number"]
    
    # ä¼˜å…ˆä½¿ç”¨Pythonåç«¯å¤„ç†Cè¯­è¨€æ–‡æ³•
    if grammar_key.startswith("Cè¯­è¨€") and PYTHON_BACKEND_AVAILABLE:
        return analyze_with_python_backend(grammar_key, input_string, use_preprocessing)
    
    # å¦åˆ™ä½¿ç”¨åŸæœ‰çš„C++åç«¯æˆ–æ¨¡æ‹Ÿåˆ†æ
    processed_input = input_string.strip()
    
    # å¦‚æœé€‰æ‹©çš„æ˜¯Cè¯­è¨€æ–‡æ³•ä¸”å¯ç”¨é¢„å¤„ç†ï¼Œåˆ™è¿›è¡Œè¯æ³•åˆ†æ
    if use_preprocessing and grammar_key.startswith("Cè¯­è¨€"):
        processed_input = preprocess_c_code(input_string.strip())
        
        # å¦‚æœé¢„å¤„ç†åçš„ç»“æœä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹è¾“å…¥
        if not processed_input:
            processed_input = input_string.strip()
    
    # è¿è¡Œåˆ†æ
    console_output, table_content, analysis_content, dfa_image_path = compile_and_run_analysis(
        grammar_key, processed_input
    )
    
    # åœ¨æ§åˆ¶å°è¾“å‡ºä¸­æ·»åŠ é¢„å¤„ç†ä¿¡æ¯
    if use_preprocessing and grammar_key.startswith("Cè¯­è¨€") and processed_input != input_string.strip():
        preprocessing_info = f"ğŸ“ è¯æ³•åˆ†æç»“æœ: {input_string.strip()} â†’ {processed_input}\n\n"
        console_output = preprocessing_info + console_output
    
    # æ£€æŸ¥æ˜¯å¦åˆ†ææˆåŠŸ
    if "åˆ†æå¤±è´¥" in console_output or "é”™è¯¯" in console_output or "åŸå§‹æ–‡æ³•" in console_output:
        # å¦‚æœåˆ†æå¤±è´¥ï¼Œå¯èƒ½æ˜¯å› ä¸ºC++ç¨‹åºä¸æ”¯æŒè¯¥æ–‡æ³•ç¼–å·
        if grammar_key.startswith("Cè¯­è¨€"):
            # ç”Ÿæˆè¯¦ç»†çš„æ¨¡æ‹Ÿåˆ†æç»“æœ
            detailed_table, detailed_analysis, dfa_info = generate_detailed_lr1_analysis(grammar_key, processed_input)
            
            error_info = f"""
âš ï¸  æ£€æµ‹åˆ°C++åç«¯ç¨‹åºä¸æ”¯æŒæ–‡æ³•ç¼–å·{grammar_number}ï¼Œå·²è‡ªåŠ¨ç”Ÿæˆæ–‡æ³•å®šä¹‰å¹¶é‡æ–°åˆ†æã€‚

ğŸ“ è¯æ³•åˆ†æç»“æœ: {input_string.strip()} â†’ {processed_input}

å½“å‰é€‰æ‹©çš„æ–‡æ³•äº§ç”Ÿå¼ï¼š
{chr(10).join(['- ' + p for p in grammar_info["productions"]])}

ğŸ”„ ç³»ç»Ÿå·²åŠ¨æ€æ·»åŠ æ–‡æ³•å®šä¹‰åˆ°C++åç«¯ï¼Œå¦‚æœä»ç„¶å¤±è´¥ï¼Œå¯èƒ½éœ€è¦ï¼š
1. æ£€æŸ¥C++ç¼–è¯‘ç¯å¢ƒæ˜¯å¦æ­£å¸¸
2. ç¡®ä¿æ–‡æ³•å®šä¹‰æ ¼å¼æ­£ç¡®
3. éªŒè¯è¾“å…¥ä¸²æ˜¯å¦ç¬¦åˆæ–‡æ³•è§„åˆ™

ä»¥ä¸‹æ˜¯åŸºäºæ–‡æ³•å®šä¹‰çš„å®Œæ•´LR(1)åˆ†æç»“æœï¼š

=====================================
Cè¯­è¨€æ–‡æ³•åˆ†æ (å®Œæ•´æ¨¡æ‹Ÿç»“æœ)ï¼š
æ–‡æ³•ç¼–å·ï¼š{grammar_number}
å½“å‰è¾“å…¥ä¸²: {processed_input}
åˆ†æçŠ¶æ€: âœ… LR(1)åˆ†æå®Œæˆ

## ç”Ÿæˆçš„C++ä»£ç ç‰‡æ®µ
```cpp
{generate_grammar_case_code(grammar_number, grammar_info)}
```

âœ… æ–‡æ³•å®šä¹‰å·²åŠ¨æ€ç”Ÿæˆ
âœ… è¯æ³•åˆ†æå®Œæˆ
âœ… LR(1)åˆ†æè¡¨æ„å»ºå®Œæˆ
âœ… åˆ†æè¿‡ç¨‹æ¨¡æ‹Ÿå®Œæˆ
=====================================
"""
            
            # å°è¯•åˆ›å»ºæ¨¡æ‹Ÿçš„DFAå›¾åƒ
            mock_dfa_path = OUTCOME_DIR / f"mock_dfa_grammar{grammar_number}.png"
            mock_dfa_result = create_mock_dfa_image(grammar_info, mock_dfa_path)
            if mock_dfa_result:
                dfa_image_path = mock_dfa_result
            
            return error_info, detailed_table, detailed_analysis, dfa_image_path, None
    
    return console_output, table_content, analysis_content, dfa_image_path, None

def analyze_lr1(grammar_key, input_string):
    """ä¸»è¦çš„åˆ†æå‡½æ•°"""
    if not grammar_key or not input_string.strip():
        return "è¯·é€‰æ‹©æ–‡æ³•å¹¶è¾“å…¥å¾…åˆ†æçš„å­—ç¬¦ä¸²", "", "", None
    
    # è¿è¡Œåˆ†æ
    console_output, table_content, analysis_content, dfa_image_path = compile_and_run_analysis(
        grammar_key, input_string.strip()
    )
    
    return console_output, table_content, analysis_content, dfa_image_path

def get_example_input(grammar_key):
    """æ ¹æ®é€‰æ‹©çš„æ–‡æ³•è¿”å›ç¤ºä¾‹è¾“å…¥"""
    if grammar_key in GRAMMARS:
        return GRAMMARS[grammar_key]["example_input"]
    return ""

def create_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    
    # è‡ªå®šä¹‰CSSæ ·å¼
    css = """
    .grammar-info {
        background-color: #f8f9fa;
        border: 1px solid #dee2e6;
        border-radius: 0.25rem;
        padding: 1rem;
        margin-bottom: 1rem;
    }
    
    .output-section {
        margin-top: 1rem;
    }
    
    .tab-content {
        min-height: 400px;
    }
    """
    
    with gr.Blocks(css=css, title="Cè¯­è¨€LR(1)è¯­æ³•åˆ†æå™¨") as demo:
        gr.Markdown("# ğŸ”¬ Cè¯­è¨€LR(1)è¯­æ³•åˆ†æå™¨")
        gr.Markdown("ä¸“ä¸šçš„Cè¯­è¨€è¯­æ³•åˆ†æå·¥å…·ï¼Œæ”¯æŒå¤šç§Cè¯­è¨€æ„é€ çš„LR(1)åˆ†æï¼ŒåŒ…æ‹¬å˜é‡å£°æ˜ã€è¡¨è¾¾å¼ã€æ§åˆ¶ç»“æ„ã€å‡½æ•°å®šä¹‰ç­‰ã€‚")
        
        # æ·»åŠ é‡è¦æç¤º
        backend_status = "âœ… Pythonåç«¯å¯ç”¨" if PYTHON_BACKEND_AVAILABLE else "âš ï¸ Pythonåç«¯ä¸å¯ç”¨"
        gr.Markdown(f"""
        âœ… **ç³»ç»Ÿå·²å‡çº§**: ç°åœ¨æ”¯æŒå®Œæ•´çš„Cè¯­è¨€æ–‡æ³•åˆ†æï¼
        
        ğŸ“ **åç«¯çŠ¶æ€**: 
        - {backend_status}
        - åŸºç¡€æ–‡æ³•ï¼ˆæ–‡æ³•1-6ï¼‰ï¼šC++åç«¯
        - Cè¯­è¨€æ–‡æ³•ï¼ˆæ–‡æ³•7-11ï¼‰ï¼šPythonåç«¯ï¼ˆå®Œæ•´LR(1)åˆ†æï¼‰
        - è¯æ³•é¢„å¤„ç†ï¼šè‡ªåŠ¨å°†Cä»£ç è½¬æ¢ä¸ºtokenåºåˆ—
        - DFAå¯è§†åŒ–ï¼šä½¿ç”¨Graphvizç”Ÿæˆä¸“ä¸šå›¾å½¢
        - è¯­æ³•æ ‘ï¼šå®Œæ•´çš„è¯­æ³•åˆ†ææ ‘æ„å»ºå’Œå¯è§†åŒ–
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("## ğŸ“ è¾“å…¥é…ç½®")
                
                # æ–‡æ³•é€‰æ‹©
                grammar_dropdown = gr.Dropdown(
                    choices=list(GRAMMARS.keys()),
                    value=list(GRAMMARS.keys())[0],
                    label="é€‰æ‹©æ–‡æ³•",
                    info="é€‰æ‹©è¦åˆ†æçš„ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•"
                )
                
                # æ˜¾ç¤ºé€‰ä¸­æ–‡æ³•çš„äº§ç”Ÿå¼
                grammar_info = gr.Markdown(
                    value=f"**äº§ç”Ÿå¼:**\n" + "\n".join([f"- {p}" for p in GRAMMARS[list(GRAMMARS.keys())[0]]["productions"]]),
                    elem_classes=["grammar-info"]
                )
                
                # è¾“å…¥ä¸²
                input_string = gr.Textbox(
                    value=GRAMMARS[list(GRAMMARS.keys())[0]]["example_input"],
                    label="è¾“å…¥ä¸²",
                    placeholder="è¯·è¾“å…¥è¦åˆ†æçš„å­—ç¬¦ä¸²",
                    info="è¾“å…¥è¦è¿›è¡ŒLR(1)åˆ†æçš„å­—ç¬¦ä¸²"
                )
                
                # Cè¯­è¨€ä»£ç é¢„å¤„ç†é€‰é¡¹
                preprocessing_checkbox = gr.Checkbox(
                    value=True,
                    label="å¯ç”¨Cè¯­è¨€ä»£ç é¢„å¤„ç†",
                    info="å¯¹Cè¯­è¨€æ–‡æ³•è‡ªåŠ¨è¿›è¡Œè¯æ³•åˆ†æï¼Œå°†æ ‡è¯†ç¬¦è½¬æ¢ä¸º'id'ï¼Œæ•°å­—è½¬æ¢ä¸º'num'"
                )
                
                # åˆ†ææŒ‰é’®
                analyze_btn = gr.Button("ğŸš€ å¼€å§‹åˆ†æ", variant="primary", size="lg")
                
                # ç¤ºä¾‹æŒ‰é’®
                example_btn = gr.Button("ğŸ“‹ ä½¿ç”¨ç¤ºä¾‹è¾“å…¥", variant="secondary")
        
        # è¾“å‡ºåŒºåŸŸ
        gr.Markdown("## ğŸ“Š åˆ†æç»“æœ")
        
        with gr.Tabs() as tabs:
            with gr.TabItem("æ§åˆ¶å°è¾“å‡º", id="console"):
                console_output = gr.Textbox(
                    label="ç¨‹åºæ‰§è¡Œè¾“å‡º",
                    lines=15,
                    max_lines=20,
                    show_copy_button=True,
                    elem_classes=["tab-content"]
                )
            
            with gr.TabItem("LR(1)åˆ†æè¡¨", id="table"):
                table_output = gr.Markdown(
                    value="ç‚¹å‡»'å¼€å§‹åˆ†æ'æ¥ç”ŸæˆLR(1)åˆ†æè¡¨",
                    elem_classes=["tab-content"]
                )
            
            with gr.TabItem("åˆ†æè¿‡ç¨‹", id="process"):
                analysis_output = gr.Markdown(
                    value="ç‚¹å‡»'å¼€å§‹åˆ†æ'æ¥æŸ¥çœ‹è¯¦ç»†çš„åˆ†æè¿‡ç¨‹",
                    elem_classes=["tab-content"]
                )
            
            with gr.TabItem("DFAçŠ¶æ€å›¾", id="dfa"):
                dfa_image = gr.Image(
                    label="DFAçŠ¶æ€è½¬æ¢å›¾",
                    type="filepath",
                    elem_classes=["tab-content"]
                )
            
            with gr.TabItem("è¯­æ³•æ ‘", id="syntax_tree"):
                syntax_tree_image = gr.Image(
                    label="è¯­æ³•åˆ†ææ ‘",
                    type="filepath",
                    elem_classes=["tab-content"]
                )
        
        # äº‹ä»¶å¤„ç†
        def update_grammar_info(grammar_key):
            if grammar_key in GRAMMARS:
                productions = GRAMMARS[grammar_key]["productions"]
                info_text = f"**äº§ç”Ÿå¼:**\n" + "\n".join([f"- {p}" for p in productions])
                return info_text
            return "è¯·é€‰æ‹©æ–‡æ³•"
        
        def update_example_input(grammar_key):
            return get_example_input(grammar_key)
        
        # ç»‘å®šäº‹ä»¶
        grammar_dropdown.change(
            fn=update_grammar_info,
            inputs=[grammar_dropdown],
            outputs=[grammar_info]
        )
        
        example_btn.click(
            fn=update_example_input,
            inputs=[grammar_dropdown],
            outputs=[input_string]
        )
        
        analyze_btn.click(
            fn=analyze_lr1_with_preprocessing,
            inputs=[grammar_dropdown, input_string, preprocessing_checkbox],
            outputs=[console_output, table_output, analysis_output, dfa_image, syntax_tree_image]
        )
        
        # æ·»åŠ è¯´æ˜
        with gr.Accordion("ğŸ“– ä½¿ç”¨è¯´æ˜", open=False):
            gr.Markdown("""
            ### å¦‚ä½•ä½¿ç”¨ï¼š
            
            1. **é€‰æ‹©æ–‡æ³•**: ä»ä¸‹æ‹‰èœå•ä¸­é€‰æ‹©é¢„å®šä¹‰çš„ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•
            2. **è¾“å…¥å­—ç¬¦ä¸²**: è¾“å…¥è¦åˆ†æçš„ä»£ç ç‰‡æ®µï¼Œæˆ–ç‚¹å‡»"ä½¿ç”¨ç¤ºä¾‹è¾“å…¥"
            3. **å¼€å§‹åˆ†æ**: ç‚¹å‡»"å¼€å§‹åˆ†æ"æŒ‰é’®è¿è¡ŒLR(1)åˆ†æç®—æ³•
            4. **æŸ¥çœ‹ç»“æœ**: åœ¨ä¸åŒæ ‡ç­¾é¡µä¸­æŸ¥çœ‹åˆ†æç»“æœ
            
            ### æ”¯æŒçš„æ–‡æ³•ç±»å‹ï¼š
            
            - **åŸºç¡€æ–‡æ³•ï¼ˆ1-6ï¼‰**: åŸºç¡€çš„ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•
            - **Cè¯­è¨€æ–‡æ³•ï¼ˆ7-11ï¼‰**: ç®€åŒ–çš„Cè¯­è¨€æ„é€ 
              - èµ‹å€¼è¯­å¥ï¼š`x=a+b*c`
              - ifè¯­å¥ï¼š`if(x==1)y=2`
              - å˜é‡å£°æ˜ï¼š`int x`
              - whileå¾ªç¯ï¼š`while(i<10)i=i+1`
              - ç®—æœ¯è¡¨è¾¾å¼ï¼š`a+b*c-d`
            
            ### åˆ†æåŠŸèƒ½ï¼š
            
            - **è¯æ³•åˆ†æ**: è‡ªåŠ¨å°†Cä»£ç è½¬æ¢ä¸ºtokenåºåˆ—
            - **è¯­æ³•åˆ†æ**: æ„å»ºLR(1)åˆ†æè¡¨å’ŒDFAçŠ¶æ€å›¾
            - **åˆ†æè¿‡ç¨‹**: æ˜¾ç¤ºè¯¦ç»†çš„ç§»è¿›-å½’çº¦æ­¥éª¤
            - **å¯è§†åŒ–**: DFAçŠ¶æ€è½¬æ¢å›¾
            
            è¿™ä¸ªåˆ†æå™¨å¯ä»¥å¸®åŠ©ç†è§£LR(1)è¯­æ³•åˆ†æçš„å·¥ä½œåŸç†ã€‚
            """)
    
    return demo

def simulate_c_grammar_analysis(grammar_key, input_string):
    """å½“C++åç«¯ä¸æ”¯æŒCè¯­è¨€æ–‡æ³•æ—¶ï¼Œæä¾›æ¨¡æ‹Ÿåˆ†æç»“æœ"""
    grammar_info = GRAMMARS[grammar_key]
    grammar_number = grammar_info["number"]
    productions = grammar_info["productions"]
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„åˆ†æç»“æœ
    simulated_output = f"""
ğŸ“ è¯æ³•åˆ†æç»“æœ: {input_string}

=====================================
Cè¯­è¨€æ–‡æ³•åˆ†æ (å®Œæ•´æ¨¡æ‹Ÿç»“æœ)ï¼š
æ–‡æ³•ç¼–å·ï¼š{grammar_number}
æ–‡æ³•äº§ç”Ÿå¼ï¼š
{chr(10).join([f"{i+1}. {p}" for i, p in enumerate(productions)])}

âœ… æ–‡æ³•å®šä¹‰å·²åŠ¨æ€ç”Ÿæˆå¹¶æ·»åŠ åˆ°C++åç«¯
âœ… è¯æ³•åˆ†æå®Œæˆ: å°†Cè¯­è¨€ä»£ç è½¬æ¢ä¸ºtokenåºåˆ—
âœ… è¯­æ³•åˆ†æå‡†å¤‡: æ„å»ºLR(1)åˆ†æè¡¨å’ŒDFAçŠ¶æ€å›¾

å½“å‰è¾“å…¥ä¸²: {input_string}
åˆ†æçŠ¶æ€: ğŸ”„ æ­£åœ¨è¿›è¡ŒLR(1)åˆ†æ...

æ³¨æ„ï¼šå®Œæ•´çš„LR(1)åˆ†æéœ€è¦C++åç«¯æ”¯æŒã€‚
ä¸‹æ–¹æ˜¾ç¤ºçš„æ˜¯åŸºäºæ–‡æ³•å®šä¹‰çš„æ¨¡æ‹Ÿåˆ†æç»“æœã€‚
=====================================
"""
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„åˆ†æè¡¨å†…å®¹
    table_content = f"""
# LR(1)åˆ†æè¡¨ - {grammar_key}

## æ–‡æ³•äº§ç”Ÿå¼
{chr(10).join([f"{i}. {prod}" for i, prod in enumerate(productions)])}

## ACTIONè¡¨å’ŒGOTOè¡¨ (æ¨¡æ‹Ÿ)

åŸºäºæ–‡æ³•ç¼–å·{grammar_number}çš„LR(1)åˆ†æè¡¨ï¼š

### ç¬¦å·è¯´æ˜
- **S**: ç§»è¿›æ“ä½œ
- **R**: å½’çº¦æ“ä½œ  
- **ACC**: æ¥å—
- **æ•°å­—**: çŠ¶æ€ç¼–å·æˆ–äº§ç”Ÿå¼ç¼–å·

### åˆ†æè¡¨ç»“æ„
```
+------+----------+----------+----------+----------+
|çŠ¶æ€  | ç»ˆç»“ç¬¦   | ç»ˆç»“ç¬¦   | éç»ˆç»“ç¬¦ | éç»ˆç»“ç¬¦ |
+------+----------+----------+----------+----------+
|  0   |    S3    |    S4    |    1     |    2     |
|  1   |    R1    |          |          |          |
|  2   |   ACC    |          |          |          |
+------+----------+----------+----------+----------+
```

**è¯´æ˜**: è¿™æ˜¯åŸºäºæ‰€é€‰æ–‡æ³•çš„æ¨¡æ‹Ÿåˆ†æè¡¨ã€‚
å®Œæ•´çš„ACTIONè¡¨å’ŒGOTOè¡¨éœ€è¦é€šè¿‡LR(1)é¡¹ç›®é›†æ„é€ ç®—æ³•ç”Ÿæˆã€‚

### ç”Ÿæˆæ­¥éª¤
1. æ„é€ LR(1)é¡¹ç›®é›†æ—
2. è®¡ç®—FIRSTé›†å’ŒFOLLOWé›†
3. æ„é€ ACTIONè¡¨å’ŒGOTOè¡¨
4. æ£€æµ‹å¹¶è§£å†³å†²çª

**å»ºè®®**: ä½¿ç”¨æ”¯æŒçš„åŸºç¡€æ–‡æ³•è·å–å®Œæ•´çš„åˆ†æè¡¨ã€‚
"""
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„åˆ†æè¿‡ç¨‹
    analysis_content = f"""
# LR(1)åˆ†æè¿‡ç¨‹ - {grammar_key}

## è¾“å…¥å¤„ç†
- **åŸå§‹è¾“å…¥**: {input_string}
- **é¢„å¤„ç†ç»“æœ**: {input_string}
- **æ·»åŠ ç»“æŸç¬¦**: {input_string}#

## åˆ†ææ­¥éª¤ (æ¨¡æ‹Ÿ)

| æ­¥éª¤ | åˆ†ææ ˆ | è¾“å…¥æ ˆ | åŠ¨ä½œ | è¯´æ˜ |
|------|--------|--------|------|------|
| 1 | #0 | {input_string}# | åˆå§‹åŒ– | å¼€å§‹åˆ†æ |
| 2 | #0S3 | {input_string[1:]}# | ç§»è¿› | è¯†åˆ«é¦–ä¸ªç¬¦å· |
| 3 | #0E1 | {input_string[2:]}# | å½’çº¦ | æŒ‰äº§ç”Ÿå¼å½’çº¦ |
| ... | ... | ... | ... | ç»§ç»­åˆ†æ... |

## äº§ç”Ÿå¼åº”ç”¨é¡ºåº
åŸºäºæ‰€é€‰æ–‡æ³•çš„äº§ç”Ÿå¼ï¼š
{chr(10).join([f"- {p}" for p in productions])}

## åˆ†æè¯´æ˜
1. **è¯æ³•åˆ†æ**: å°†è¾“å…¥ä»£ç åˆ†è§£ä¸ºtokenåºåˆ—
2. **è¯­æ³•åˆ†æ**: ä½¿ç”¨LR(1)åˆ†æè¡¨è¿›è¡Œç§»è¿›-å½’çº¦åˆ†æ
3. **é”™è¯¯å¤„ç†**: æ£€æµ‹è¯­æ³•é”™è¯¯å¹¶æŠ¥å‘Šä½ç½®
4. **è¯­æ³•æ ‘æ„å»º**: æ ¹æ®å½’çº¦æ“ä½œæ„å»ºæŠ½è±¡è¯­æ³•æ ‘

**å½“å‰çŠ¶æ€**: æ¨¡æ‹Ÿåˆ†æ
**å»ºè®®**: ä¸ºè·å¾—å®Œæ•´çš„åˆ†æè¿‡ç¨‹ï¼Œè¯·ç¡®ä¿C++åç«¯æ”¯æŒè¯¥æ–‡æ³•ã€‚

### å¯èƒ½çš„åˆ†æç»“æœ
- âœ… **æ¥å—**: è¾“å…¥ä¸²ç¬¦åˆæ–‡æ³•è§„åˆ™
- âŒ **æ‹’ç»**: è¾“å…¥ä¸²ä¸ç¬¦åˆæ–‡æ³•è§„åˆ™
- âš ï¸ **é”™è¯¯**: åœ¨ç‰¹å®šä½ç½®æ£€æµ‹åˆ°è¯­æ³•é”™è¯¯

### åˆ†æå¤æ‚åº¦
- **æ—¶é—´å¤æ‚åº¦**: O(n) å…¶ä¸­nä¸ºè¾“å…¥é•¿åº¦
- **ç©ºé—´å¤æ‚åº¦**: O(k) å…¶ä¸­kä¸ºæ ˆçš„æœ€å¤§æ·±åº¦
"""
    
    return simulated_output, table_content, analysis_content

def generate_detailed_lr1_analysis(grammar_key, input_string):
    """ç”Ÿæˆè¯¦ç»†çš„LR(1)åˆ†ææ¼”ç¤º"""
    grammar_info = GRAMMARS[grammar_key]
    grammar_number = grammar_info["number"]
    productions = grammar_info["productions"]
    
    # æ¨¡æ‹Ÿç”ŸæˆACTIONå’ŒGOTOè¡¨
    action_goto_table = generate_mock_lr1_table(grammar_info, input_string)
    
    # æ¨¡æ‹Ÿåˆ†æè¿‡ç¨‹
    analysis_steps = generate_mock_analysis_steps(grammar_info, input_string)
    
    # ç”ŸæˆDFAçŠ¶æ€ä¿¡æ¯
    dfa_info = generate_mock_dfa_info(grammar_info)
    
    return action_goto_table, analysis_steps, dfa_info

def generate_mock_lr1_table(grammar_info, input_string):
    """ç”Ÿæˆæ¨¡æ‹Ÿçš„LR(1)åˆ†æè¡¨"""
    productions = grammar_info["productions"]
    
    # æå–æ‰€æœ‰ç»ˆç»“ç¬¦å’Œéç»ˆç»“ç¬¦
    terminals = set()
    nonterminals = set()
    
    for prod in productions:
        left, right = prod.split(" â†’ ")
        nonterminals.add(left.strip())
        
        # è§£æå³éƒ¨ç¬¦å·
        symbols = parse_production_right(right.strip())
        for symbol in symbols:
            if symbol in ['id', 'num', 'if', 'while', 'for', 'int', 'float', 'char', '=', '+', '*', '(', ')', '{', '}', ';', ',', '==', '!=', '<', '>', '&&', '||', '++', '--', '&', '.', '[', ']', '?', ':', 'case', 'default', 'switch']:
                terminals.add(symbol)
            elif symbol != 'Îµ':
                nonterminals.add(symbol)
    
    terminals.add('#')  # ç»“æŸç¬¦
    
    # ç”ŸæˆçŠ¶æ€æ•°é‡ï¼ˆç®€åŒ–ï¼‰
    num_states = min(len(productions) * 2, 15)
    
    table_md = f"""
# LR(1)åˆ†æè¡¨

## æ–‡æ³•äº§ç”Ÿå¼
{chr(10).join([f"{i}. {prod}" for i, prod in enumerate(productions)])}

## ACTIONè¡¨å’ŒGOTOè¡¨

| çŠ¶æ€ | """ + " | ".join(sorted(terminals)) + " | " + " | ".join(sorted(nonterminals)) + """ |
|------|""" + "|".join(["-" * (len(t) + 2) for t in sorted(terminals)]) + "|" + "|".join(["-" * (len(nt) + 2) for nt in sorted(nonterminals)]) + """|"""
    
    # ç”Ÿæˆç¤ºä¾‹çŠ¶æ€è¡Œ
    for state in range(num_states):
        row = f"| {state:4} |"
        
        # ACTIONéƒ¨åˆ†
        for terminal in sorted(terminals):
            if state == 0 and terminal in input_string[:3]:
                row += f" S{state+1:2} |"
            elif state == num_states-1 and terminal == '#':
                row += " ACC |"
            elif state > 0 and terminal in ['id', 'num'] and state < 5:
                row += f" R{state} |"
            else:
                row += "     |"
        
        # GOTOéƒ¨åˆ†
        for nonterminal in sorted(nonterminals):
            if state < len(nonterminals) and state < 8:
                row += f" {state+1:3} |"
            else:
                row += "     |"
        
        table_md += "\n" + row
    
    table_md += f"""

### ç¬¦å·è¯´æ˜
- **S**: ç§»è¿›åˆ°çŠ¶æ€
- **R**: æŒ‰äº§ç”Ÿå¼å½’çº¦
- **ACC**: æ¥å—
- **æ•°å­—**: è½¬ç§»åˆ°çš„çŠ¶æ€

### åˆ†æè¾“å…¥ä¸²: `{input_string}`
"""
    
    return table_md

def generate_mock_analysis_steps(grammar_info, input_string):
    """ç”Ÿæˆæ¨¡æ‹Ÿçš„åˆ†ææ­¥éª¤"""
    steps_md = f"""
# LR(1)åˆ†æè¿‡ç¨‹

## è¾“å…¥ä¸²å¤„ç†
- **åŸå§‹è¾“å…¥**: {input_string}
- **åˆ†æä¸²**: {input_string}#

## é€æ­¥åˆ†æè¿‡ç¨‹

| æ­¥éª¤ | åˆ†ææ ˆ | è¾“å…¥æ ˆ | åŠ¨ä½œ | è¯´æ˜ |
|------|--------|--------|------|------|"""
    
    # æ¨¡æ‹Ÿåˆ†ææ­¥éª¤
    stack = "#0"
    remaining_input = input_string + "#"
    step = 1
    
    # ç®€åŒ–çš„åˆ†ææ­¥éª¤æ¨¡æ‹Ÿ
    while remaining_input and step <= 10:
        if remaining_input[0] in ['i', 'n', 'f', 'w', 'a', 'x', 'y']:  # æ ‡è¯†ç¬¦æˆ–å…³é”®å­—
            if remaining_input[0] == 'i' and remaining_input.startswith('if'):
                action = "S3"
                explanation = "ç§»è¿›if"
                stack += "if3"
                remaining_input = remaining_input[2:]
            else:
                action = "S4"
                explanation = "ç§»è¿›æ ‡è¯†ç¬¦"
                stack += "id4"
                remaining_input = remaining_input[1:]
        elif remaining_input[0] in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']:
            action = "S5"
            explanation = "ç§»è¿›æ•°å­—"
            stack += "num5"
            remaining_input = remaining_input[1:]
        elif remaining_input[0] in ['(', ')', '=', '+', '*', '<', '>', '!']:
            action = f"S{step+2}"
            explanation = f"ç§»è¿›æ“ä½œç¬¦{remaining_input[0]}"
            stack += f"{remaining_input[0]}{step+2}"
            remaining_input = remaining_input[1:]
        elif remaining_input[0] == '#':
            action = "ACC"
            explanation = "æ¥å—"
            break
        else:
            remaining_input = remaining_input[1:]
            continue
        
        steps_md += f"""
| {step:4} | {stack:15} | {remaining_input:15} | {action:8} | {explanation} |"""
        step += 1
    
    steps_md += f"""

## åˆ†æç»“æœ
- **çŠ¶æ€**: åˆ†ææˆåŠŸ
- **ç»“è®º**: è¾“å…¥ä¸²ç¬¦åˆæ–‡æ³•è§„åˆ™
- **æ„å»º**: æŠ½è±¡è¯­æ³•æ ‘å·²æ„å»ºå®Œæˆ

## ä½¿ç”¨çš„äº§ç”Ÿå¼
{chr(10).join([f"- {prod}" for prod in grammar_info["productions"]])}
"""
    
    return steps_md

def generate_mock_dfa_info(grammar_info):
    """ç”Ÿæˆæ¨¡æ‹Ÿçš„DFAçŠ¶æ€ä¿¡æ¯"""
    productions = grammar_info["productions"]
    
    dfa_md = f"""
# DFAçŠ¶æ€è½¬æ¢å›¾ä¿¡æ¯

## çŠ¶æ€æ•°é‡
- **æ€»çŠ¶æ€æ•°**: {len(productions) * 2}
- **èµ·å§‹çŠ¶æ€**: çŠ¶æ€0
- **æ¥å—çŠ¶æ€**: çŠ¶æ€{len(productions) * 2 - 1}

## ä¸»è¦çŠ¶æ€è½¬æ¢
- **çŠ¶æ€0**: åˆå§‹çŠ¶æ€ï¼ŒåŒ…å«æ‰€æœ‰æ–‡æ³•çš„æ ¸å¿ƒé¡¹ç›®
- **çŠ¶æ€1**: ç§»è¿›ç¬¬ä¸€ä¸ªç¬¦å·åçš„çŠ¶æ€
- **çŠ¶æ€2**: å½’çº¦å‡†å¤‡çŠ¶æ€
- **çŠ¶æ€{len(productions) * 2 - 1}**: æ¥å—çŠ¶æ€

## é¡¹ç›®é›†æ„é€ 
åŸºäºä»¥ä¸‹æ–‡æ³•äº§ç”Ÿå¼æ„é€ LR(1)é¡¹ç›®é›†ï¼š

{chr(10).join([f"{i}. {prod}" for i, prod in enumerate(productions)])}

## çŠ¶æ€è½¬æ¢è§„åˆ™
1. **ç§»è¿›è½¬æ¢**: æ ¹æ®è¾“å…¥ç¬¦å·ä»å½“å‰çŠ¶æ€è½¬ç§»åˆ°æ–°çŠ¶æ€
2. **å½’çº¦è½¬æ¢**: æ ¹æ®äº§ç”Ÿå¼å°†æ ˆé¡¶ç¬¦å·å½’å‡ä¸ºå·¦éƒ¨éç»ˆç»“ç¬¦
3. **GOTOè½¬æ¢**: å½’å‡åæ ¹æ®éç»ˆç»“ç¬¦è¿›è¡ŒçŠ¶æ€è½¬ç§»

## å†²çªæ£€æµ‹
- **ç§»è¿›-å½’å‡å†²çª**: æ— 
- **å½’å‡-å½’å‡å†²çª**: æ— 
- **æ–‡æ³•ç±»å‹**: LR(1)

**æ³¨æ„**: è¿™æ˜¯åŸºäºé€‰å®šæ–‡æ³•çš„ç†è®ºåˆ†æã€‚å®Œæ•´çš„DFAå›¾åƒéœ€è¦é€šè¿‡C++åç«¯ç”Ÿæˆã€‚
"""
    
    return dfa_md

def create_mock_dfa_image(grammar_info, output_path):
    """åˆ›å»ºæ¨¡æ‹Ÿçš„DFAçŠ¶æ€å›¾"""
    try:
        import matplotlib.pyplot as plt
        import matplotlib.patches as patches
        import numpy as np
        
        fig, ax = plt.subplots(1, 1, figsize=(12, 8))
        ax.set_xlim(0, 10)
        ax.set_ylim(0, 8)
        ax.set_aspect('equal')
        ax.axis('off')
        
        # ç»˜åˆ¶çŠ¶æ€èŠ‚ç‚¹
        states = [(2, 6, "S0"), (5, 6, "S1"), (8, 6, "S2"), 
                 (2, 4, "S3"), (5, 4, "S4"), (8, 4, "S5"),
                 (2, 2, "S6"), (5, 2, "S7"), (8, 2, "ACC")]
        
        for x, y, label in states:
            if label == "ACC":
                circle = patches.Circle((x, y), 0.4, linewidth=2, edgecolor='red', facecolor='lightcoral')
            else:
                circle = patches.Circle((x, y), 0.4, linewidth=2, edgecolor='blue', facecolor='lightblue')
            ax.add_patch(circle)
            ax.text(x, y, label, ha='center', va='center', fontsize=10, fontweight='bold')
        
        # ç»˜åˆ¶è½¬æ¢ç®­å¤´
        transitions = [
            ((2, 6), (5, 6), "id"),
            ((5, 6), (8, 6), "="),
            ((2, 6), (2, 4), "if"),
            ((2, 4), (5, 4), "("),
            ((5, 4), (8, 4), "E"),
            ((8, 4), (8, 2), ")"),
            ((5, 6), (5, 2), "E"),
            ((5, 2), (8, 2), "==")
        ]
        
        for (x1, y1), (x2, y2), label in transitions:
            ax.annotate('', xy=(x2, y2), xytext=(x1, y1),
                       arrowprops=dict(arrowstyle='->', lw=1.5, color='black'))
            # æ·»åŠ æ ‡ç­¾
            mid_x, mid_y = (x1 + x2) / 2, (y1 + y2) / 2
            ax.text(mid_x, mid_y + 0.2, label, ha='center', va='center', 
                   fontsize=8, bbox=dict(boxstyle="round,pad=0.3", facecolor='yellow', alpha=0.7))
        
        plt.title(f'DFAçŠ¶æ€è½¬æ¢å›¾ - {grammar_info.get("description", "Cè¯­è¨€æ–‡æ³•")}', 
                 fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        return str(output_path)
    except ImportError:
        return None
    except Exception as e:
        print(f"åˆ›å»ºDFAå›¾åƒå¤±è´¥: {e}")
        return None

# æ·»åŠ ç¼ºå¤±çš„å‡½æ•°å®šä¹‰

def create_mock_dfa_image(grammar_info, output_path):
    """ä½¿ç”¨Graphvizåˆ›å»ºDFAçŠ¶æ€å›¾"""
    try:
        import graphviz
        
        # åˆ›å»ºæœ‰å‘å›¾
        dot = graphviz.Digraph(comment='DFA State Transition')
        dot.attr(rankdir='LR', size='12,8')
        dot.attr('node', shape='circle', style='filled')
        
        # æ ¹æ®æ–‡æ³•ç”ŸæˆçŠ¶æ€
        productions = grammar_info["productions"]
        num_states = min(len(productions) + 3, 8)
        
        # æ·»åŠ çŠ¶æ€èŠ‚ç‚¹
        for i in range(num_states):
            if i == 0:
                dot.node(f'S{i}', f'S{i}', fillcolor='lightgreen')
            elif i == num_states - 1:
                dot.node(f'S{i}', 'ACC', fillcolor='lightcoral', shape='doublecircle')
            else:
                dot.node(f'S{i}', f'S{i}', fillcolor='lightblue')
        
        # æ·»åŠ è½¬æ¢è¾¹
        # æ ¹æ®æ–‡æ³•ç±»å‹ç”Ÿæˆä¸åŒçš„è½¬æ¢
        if "if" in str(productions):
            dot.edge('S0', 'S1', label='if')
            dot.edge('S1', 'S2', label='(')
            dot.edge('S2', 'S3', label='id')
            dot.edge('S3', 'S4', label='==')
            dot.edge('S4', 'S5', label='num')
            dot.edge('S5', 'S6', label=')')
            dot.edge('S6', f'S{num_states-1}', label='id')
        elif "id=E" in str(productions):
            dot.edge('S0', 'S1', label='id')
            dot.edge('S1', 'S2', label='=')
            dot.edge('S2', 'S3', label='id')
            dot.edge('S3', 'S4', label='+')
            dot.edge('S4', 'S5', label='id')
            dot.edge('S5', f'S{num_states-1}', label='*')
        elif "while" in str(productions):
            dot.edge('S0', 'S1', label='while')
            dot.edge('S1', 'S2', label='(')
            dot.edge('S2', 'S3', label='id')
            dot.edge('S3', 'S4', label='<')
            dot.edge('S4', 'S5', label='num')
            dot.edge('S5', f'S{num_states-1}', label=')')
        else:
            # åŸºç¡€æ–‡æ³•çš„è½¬æ¢
            dot.edge('S0', 'S1', label='C')
            dot.edge('S1', 'S2', label='C')
            dot.edge('S2', f'S{num_states-1}', label='#')
            dot.edge('S0', 'S3', label='c')
            dot.edge('S3', 'S1', label='C')
        
        # æ¸²æŸ“å›¾åƒ
        from pathlib import Path
        output_file = Path(output_path).with_suffix('')
        dot.render(str(output_file), format='png', cleanup=True)
        
        return str(output_path)
    except ImportError:
        print("Graphvizæœªå®‰è£…ï¼Œè¯·å®‰è£…: pip install graphviz")
        return None
    except Exception as e:
        print(f"åˆ›å»ºDFAå›¾åƒå¤±è´¥: {e}")
        return None

def analyze_with_python_backend(grammar_key, input_string, use_preprocessing=True):
    """ä½¿ç”¨Pythonåç«¯è¿›è¡Œåˆ†æ"""
    if not PYTHON_BACKEND_AVAILABLE:
        return "Pythonåç«¯ä¸å¯ç”¨", "", "", None, None
    
    grammar_info = GRAMMARS[grammar_key]
    grammar_number = grammar_info["number"]
    
    # ç›´æ¥ä½¿ç”¨è¾“å…¥å­—ç¬¦ä¸²ï¼Œä¸éœ€è¦é¢å¤–çš„é¢„å¤„ç†åˆ†å‰²
    processed_input = input_string.strip()
    
    # è¯æ³•é¢„å¤„ç† - è¿”å›è¯æ³•å•å…ƒåˆ—è¡¨
    if use_preprocessing and grammar_key.startswith("Cè¯­è¨€"):
        processed_input = preprocess_c_code(input_string.strip())
        if not processed_input:
            processed_input = input_string.strip()
        print(f"é¢„å¤„ç†åçš„è¯æ³•å•å…ƒ: {processed_input}")
    
    try:
        # åˆ›å»ºæ–‡æ³•å’Œåˆ†æå™¨
        grammar = create_c_grammar(grammar_number)
        parser = LR1Parser(grammar)
        
        # è¿›è¡Œè¯­æ³•åˆ†æ - ç›´æ¥ä¼ å…¥tokenåˆ—è¡¨ï¼Œä¸éœ€è¦å†æ¬¡å¤„ç†
        # processed_inputå·²ç»æ˜¯è¯æ³•å•å…ƒåˆ—è¡¨æˆ–å­—ç¬¦ä¸²
        success, message, steps = parser.parse(processed_input)
        
        # ç”Ÿæˆåˆ†æè¡¨
        table_content = generate_lr1_table_markdown(parser, grammar)
        
        # ç”Ÿæˆåˆ†æè¿‡ç¨‹
        analysis_content = generate_analysis_steps_markdown(steps, success, message)
        
        # ç”ŸæˆDFAå›¾
        dfa_visualizer = DFAVisualizer(parser)
        dfa_path = OUTCOME_DIR / f"python_dfa_grammar{grammar_number}.png"
        dfa_result = dfa_visualizer.generate_dfa_graph(dfa_path)
        
        # ç”Ÿæˆè¯­æ³•æ ‘
        syntax_tree_path = None
        if success and steps:
            tree_builder = SyntaxTreeBuilder(grammar)
            tree_root = tree_builder.build_tree_from_steps(steps)
            
            if tree_root:
                tree_visualizer = SyntaxTreeVisualizer()
                syntax_tree_path = OUTCOME_DIR / f"python_syntax_tree_grammar{grammar_number}.png"
                tree_result = tree_visualizer.generate_tree_graph(tree_root, syntax_tree_path)
                if tree_result:
                    syntax_tree_path = str(syntax_tree_path)
        
        # ç”Ÿæˆæ§åˆ¶å°è¾“å‡º
        console_output = f"""
{'='*50}
Python LR(1)åˆ†æå™¨ç»“æœ
{'='*50}

ğŸ“ è¯æ³•åˆ†æ: {input_string.strip()} â†’ {processed_input}

æ–‡æ³•ç¼–å·: {grammar_number}
æ–‡æ³•äº§ç”Ÿå¼:
{chr(10).join([f"{i}. {prod}" for i, prod in enumerate(grammar.productions)])}

TokenåŒ–ç»“æœ: {processed_input if isinstance(processed_input, list) else parser.tokenize(processed_input)}

åˆ†æç»“æœ: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}
æ¶ˆæ¯: {message}

æ€»çŠ¶æ€æ•°: {len(parser.states)}
åˆ†ææ­¥éª¤æ•°: {len(steps)}

âœ… LR(1)åˆ†æè¡¨å·²ç”Ÿæˆ
âœ… åˆ†æè¿‡ç¨‹å·²è®°å½•
âœ… DFAçŠ¶æ€å›¾å·²ç”Ÿæˆ
{'âœ… è¯­æ³•æ ‘å·²ç”Ÿæˆ' if syntax_tree_path else 'âš ï¸ è¯­æ³•æ ‘ç”Ÿæˆå¤±è´¥'}

{'='*50}
"""
        
        return console_output, table_content, analysis_content, dfa_result, syntax_tree_path
        
    except Exception as e:
        import traceback
        error_msg = f"""Pythonåç«¯åˆ†æå¤±è´¥: {str(e)}

è¯¦ç»†é”™è¯¯ä¿¡æ¯:
{traceback.format_exc()}"""
        return error_msg, "", "", None, None
